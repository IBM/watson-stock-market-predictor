{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PREDICTING THE STOCK MARKET WITH WATSON\n",
    "\n",
    "## Part 2: Introduction\n",
    "\n",
    "In this Jupyter Notebook you'll learn step-by-step how to use the Watson Machine Learning API that was automatically generated when the previously created WS Modeler flow was deployed. You will also learn how to download files from IBM Cloud Object Storage and generate interactive visualizations using `Bokeh`. \n",
    "\n",
    "This Notebook is part of the series on stock market forecasting.\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "#### 1. Using the Watson Machine Learning Python Client\n",
    "* 1.1: Setting up WML Credentials and Client\n",
    "* 1.2: Preparing Input Data\n",
    "* 1.3: Making an API Call to WML\n",
    "* 1.4: Parsing the WML results\n",
    "\n",
    "#### 2. Visualizing the Results\n",
    "* 2.1: Plotting the Modeler Flow Forecasts\n",
    "* 2.2: Validating Modeler Flow Forecasts with Observed Data\n",
    "* 2.3: Interacting with Complete Historic and Forecasted Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1: Using the Watson Machine Learning Python Client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Previously, we trained a time series forecaster in Watson Modeler Flow and later deployed this forecaster in a Watson Machine Learning service instance.\n",
    "\n",
    "Now, in this section, we will use the WML API to send new input data to our time series forecaster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1: Setting up WML Credentials and Client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Go to the the IBM Cloud portal and access your Watson Machine Learning instance.\n",
    "\n",
    "Copy your credentials in the variable in the next cell, as shown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ibm_watson_machine_learning import APIClient\n",
    "print('Packages imported.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wml_credentials = {\n",
    "    \"apikey\": \"\",\n",
    "    \"url\": \"\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = APIClient(wml_credentials)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, paste the scoring_endpoint link you copied in the first part of this code pattern into the variable below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring_endpoint = \"\""
   ]
  },
  {
   "source": [
    "Now, paste the Space ID from Settings of the Deployment Space for this Watson Machine Learning Service in the variable below."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "space_uid = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2: Preparing Input Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `payload` dict will contain only some points of data for demonstration. \n",
    "\n",
    "This payload must be a dict type with the same structure as the csv file prepared with Data Refinery in Watson Studio.\n",
    "\n",
    "Remember that the `WIKI/TABLE` Quandl database only goes until 27-March-2018."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: manually define and pass the array(s) of values to be scored in the next line\n",
    "payload = {\n",
    "    \"fields\": [\"Date\", \"Open\", \"High\", \"Low\", \"Close\"],\n",
    "    \"values\": [['2017-03-28', 140.91, 144.04, 140.62, 143.80]]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3: Making an API Call to WML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next code cell executes a HTTP request to WML with the payload as input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = wml_client.deployments.score(scoring_endpoint, payload)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before using `Bokeh` to interact with the data, we need to parse it in a Pandas dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4: Parsing the WML Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "\n",
    "def parse(dic):\n",
    "    for k, v in dic.items():\n",
    "        if isinstance(v, dict):\n",
    "            for p in parse(v):\n",
    "                yield [k] + p\n",
    "        else:\n",
    "            yield [k, v]\n",
    "\n",
    "lst = list(parse(data))\n",
    "columns = lst[0][1]\n",
    "values = lst[1][1]\n",
    "\n",
    "def parse(values):\n",
    "    for k in values:\n",
    "        string_lst = k[0].split(\" \")\n",
    "        k[0] = datetime.strptime(string_lst[0], '%Y-%m-%d')\n",
    "\n",
    "parse(values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code cell above transformed the `dict` response into two lists: the labels (columns) and rows (values)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we just create a new Pandas dataframe with the future data for Apple Inc. stocks, retrieved from WML using the API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "ndf = pd.DataFrame.from_records(values, columns=columns)\n",
    "print(ndf.info())\n",
    "ndf.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2: Validating and Visualizing the Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --user bokeh==1.0.4 --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bokeh.plotting import figure, output_file, show\n",
    "from bokeh.models import ColumnDataSource\n",
    "from bokeh.embed import components\n",
    "from bokeh.io import output_notebook\n",
    "\n",
    "print('Packages imported.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load bokeh\n",
    "output_notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1: Plotting the Modeler Flow Forecasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure\n",
    "p = figure(plot_width=1200, plot_height=550, title='Historic and Predicted Stock Value Data', x_axis_type=\"datetime\")\n",
    "\n",
    "# Plot Lines\n",
    "p.line(ndf.Date, ndf['$TS-Close'], line_width=3, line_color=\"#ff6699\", legend='Modeled Close Value')\n",
    "p.line(ndf.Date, ndf['$TS-Open'], line_width=3, line_color=\"#0099ff\", legend='Modeled Open Value')\n",
    "p.line(ndf.Date, ndf['$TSLCI-Close'], line_width=0.5, line_color=\"#ff6699\", legend='Modeled Close Value Bounds')\n",
    "p.line(ndf.Date, ndf['$TSUCI-Close'], line_width=0.5, line_color=\"#ff6699\", legend='Modeled Close Value Bounds')\n",
    "p.line(ndf.Date, ndf['$TSLCI-Open'], line_width=0.5, line_color=\"#0099ff\", legend='Modeled Open Value Bounds')\n",
    "p.line(ndf.Date, ndf['$TSUCI-Open'], line_width=0.5, line_color=\"#0099ff\", legend='Modeled Open Value Bounds')\n",
    "\n",
    "# Axis and Labels\n",
    "p.legend.orientation = \"vertical\"\n",
    "p.legend.location = \"top_left\"\n",
    "p.xaxis.axis_label = \"Date\"\n",
    "p.xaxis.axis_label_text_font_style = 'bold'\n",
    "p.xaxis.axis_label_text_font_size = '16pt'\n",
    "p.xaxis.major_label_text_font_size = '14pt'\n",
    "p.yaxis.axis_label = \"Value ($ USD)\"\n",
    "p.yaxis.axis_label_text_font_style = 'bold'\n",
    "p.yaxis.axis_label_text_font_size = '16pt'\n",
    "p.yaxis.major_label_text_font_size = '12pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3: Validating Modeler Flow Forecasts with Observed Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Click on the `0100` button on the top right corner here in Watson Studio, and select the `AAPL.csv_shaped.csv` file and then Insert to code -> Insert pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import types\n",
    "import pandas as pd\n",
    "from botocore.client import Config\n",
    "import ibm_boto3\n",
    "\n",
    "def __iter__(self): return 0\n",
    "\n",
    "# @hidden_cell\n",
    "# The following code accesses a file in your IBM Cloud Object Storage. It includes your credentials.\n",
    "# You might want to remove those credentials before you share the notebook.\n",
    "client_a4bf3cc686cc4ca6a966bdc9f46ae2b8 = ibm_boto3.client(service_name='s3',\n",
    "    ibm_api_key_id='FgBUyGAWCMntsRuRqPvme8kHGRDJEnnx5W_yfnEohzFC',\n",
    "    ibm_auth_endpoint=\"https://iam.ng.bluemix.net/oidc/token\",\n",
    "    config=Config(signature_version='oauth'),\n",
    "    endpoint_url='https://s3-api.us-geo.objectstorage.service.networklayer.com')\n",
    "\n",
    "body = client_a4bf3cc686cc4ca6a966bdc9f46ae2b8.get_object(Bucket='watsonstockmarketpredictor-donotdelete-pr-gfd7hukq2auktz',Key='data_asset/AAPL.csv_shaped_531cec44.csv')['Body']\n",
    "# add missing __iter__ method, so pandas accepts body as file-like object\n",
    "if not hasattr(body, \"__iter__\"): body.__iter__ = types.MethodType( __iter__, body )\n",
    "\n",
    "df_data_1 = pd.read_csv(body)\n",
    "df_data_1.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we split the full historical data into a train and a test dataset:\n",
    "import datetime\n",
    "\n",
    "split_date = datetime.date(2015, 1, 2)\n",
    "#df_train = df_data_1[(pd.to_datetime(df_data_1[\"Date\"]) < split_date)]\n",
    "df_test = df_data_1[(pd.to_datetime(df_data_1[\"Date\"]) > split_date)]\n",
    "df_test['Date'] = df_test['Date'].apply(lambda x: datetime.datetime.strptime(x,'%Y-%m-%d'))\n",
    "df_test = df_test.sort_values(['Date'])\n",
    "df_test.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure\n",
    "p = figure(plot_width=1200, plot_height=550, title='Historic and Predicted Stock Value Data', x_axis_type=\"datetime\")\n",
    "\n",
    "# Plot Lines\n",
    "p.line(ndf.Date, ndf['$TS-Close'], line_width=3, line_color=\"#ff6699\", legend='Forecasted Close Value')\n",
    "p.line(ndf.Date, ndf['$TS-Open'], line_width=3, line_color=\"#0099ff\", legend='Forecasted Open Value')\n",
    "p.line(df_test.Date, df_test.Close, line_width=0.5, line_color=\"#ff6699\", legend='Historic Close Data (Test Sample)')\n",
    "p.line(df_test.Date, df_test.Open, line_width=0.5, line_color=\"#0099ff\", legend='Historic Open Data (Test Sample)')\n",
    "\n",
    "# Axis and Labels\n",
    "p.legend.orientation = \"vertical\"\n",
    "p.legend.location = \"top_left\"\n",
    "p.xaxis.axis_label = \"Date\"\n",
    "p.xaxis.axis_label_text_font_style = 'bold'\n",
    "p.xaxis.axis_label_text_font_size = '16pt'\n",
    "p.xaxis.major_label_text_font_size = '14pt'\n",
    "p.yaxis.axis_label = \"Value ($ USD)\"\n",
    "p.yaxis.axis_label_text_font_style = 'bold'\n",
    "p.yaxis.axis_label_text_font_size = '16pt'\n",
    "p.yaxis.major_label_text_font_size = '12pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndf_filtered = ndf.drop(['Close', 'Open', '$TSResidual-Open', '$TSResidual-Close'], axis=1)\n",
    "\n",
    "result = pd.concat([ndf_filtered, df_test], axis=1).dropna()\n",
    "result = result.loc[:,~result.columns.duplicated()]\n",
    "result = result.sort_values(['Date'])\n",
    "result.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next cell, simple mean errors are calculated (percentual and absolute):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "open_abs_errors = []\n",
    "close_abs_errors = []\n",
    "open_pct_errors = []\n",
    "close_pct_errors = []\n",
    "\n",
    "for index, row in result.iterrows():\n",
    "    open_abs_errors.append(abs(row['Open']-row['$TS-Open']))\n",
    "    close_abs_errors.append(abs(row['Close']-row['$TS-Close']))\n",
    "    open_pct_errors.append((abs(row['Open']-row['$TS-Open']))/row['Open'])\n",
    "    close_pct_errors.append((abs(row['Close']-row['$TS-Close']))/row['Close'])\n",
    "    \n",
    "mean_open_error = sum(open_abs_errors) / len(open_abs_errors)\n",
    "mean_close_error = sum(close_abs_errors) / len(close_abs_errors)\n",
    "mean_open_pct_error = sum(open_pct_errors) / len(open_pct_errors)\n",
    "mean_close_pct_error = sum(close_pct_errors) / len(close_pct_errors)\n",
    "\n",
    "print('Mean Errors in 1-Year Future Prediction:')\n",
    "print('Analyzed Stock: AAPL (Apple Inc.)')\n",
    "print('----------------------------------------')\n",
    "print('Mean Open Value Error (USD): {} $'.format(round(mean_open_error, 3)))\n",
    "print('Mean Close Value Error (USD): {} $'.format(round(mean_close_error, 3)))\n",
    "print('Mean Open Value Error: {}%'.format(round(mean_open_pct_error*100, 3)))\n",
    "print('Mean Close Value Error: {}%'.format(round(mean_close_pct_error*100, 3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3: Interacting with Complete Historic and Forecasted Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure\n",
    "p = figure(plot_width=1200, plot_height=550, title='Historic and Predicted Stock Value Data', x_axis_type=\"datetime\")\n",
    "\n",
    "# Plot Lines\n",
    "p.line(ndf.Date, ndf['$TSLCI-Close'], line_width=0.5, line_color=\"#ff6699\", legend='Modeled Close Value Bounds')\n",
    "p.line(ndf.Date, ndf['$TSUCI-Close'], line_width=0.5, line_color=\"#ff6699\", legend='Modeled Close Value Bounds')\n",
    "p.line(ndf.Date, ndf['$TSLCI-Open'], line_width=0.5, line_color=\"#0099ff\", legend='Modeled Open Value Bounds')\n",
    "p.line(ndf.Date, ndf['$TSUCI-Open'], line_width=0.5, line_color=\"#0099ff\", legend='Modeled Open Value Bounds')\n",
    "\n",
    "p.line(ndf.Date, ndf['$TS-Close'], line_width=3, line_color=\"#ff6699\", legend='Forecasted Close Value')\n",
    "p.line(ndf.Date, ndf['$TS-Open'], line_width=3, line_color=\"#0099ff\", legend='Forecasted Open Value')\n",
    "p.line(df_test['Date'], df_test['Close'], line_width=0.5, line_color=\"#ff6699\", legend='Historic Close Data (Test Sample)')\n",
    "p.line(df_test['Date'], df_test['Open'], line_width=0.5, line_color=\"#0099ff\", legend='Historic Open Data (Test Sample)')\n",
    "\n",
    "# Axis and Labels\n",
    "p.legend.orientation = \"vertical\"\n",
    "p.legend.location = \"top_left\"\n",
    "p.xaxis.axis_label = \"Date\"\n",
    "p.xaxis.axis_label_text_font_style = 'bold'\n",
    "p.xaxis.axis_label_text_font_size = '16pt'\n",
    "p.xaxis.major_label_text_font_size = '14pt'\n",
    "p.yaxis.axis_label = \"Value ($ USD)\"\n",
    "p.yaxis.axis_label_text_font_style = 'bold'\n",
    "p.yaxis.axis_label_text_font_size = '16pt'\n",
    "p.yaxis.major_label_text_font_size = '12pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "show(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "This notebook and its source code is made available under the terms of the <a href = \"https://github.com/IBM/watson-stock-market-predictor/blob/master/LICENSE\">Apache License 2.0</a>.\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Thank you for completing this journey!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
